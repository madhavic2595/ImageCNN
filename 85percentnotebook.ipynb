{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble 3 Models in VGG. \n",
    "#Model 1 -> ZCA + FeatureWise\n",
    "#Model 2 -> Only Featurewise Normalization \n",
    "#Model 3  -> None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "device_name\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, AveragePooling2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = np.load('E:/Kaggle2/train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "x = train_ds['arr_0']\n",
    "y = train_ds['arr_1']\n",
    "\n",
    "x = x.reshape(1500,28,28,1)\n",
    "print(y.shape)\n",
    "\n",
    "#import numpy, scipy.sparse\n",
    "#from scipy.sparse import csr_matrix\n",
    "#Asp = scipy.sparse.csr_matrix(x)\n",
    "#print(type(Asp))\n",
    "\n",
    "#M=sparse.coo_matrix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Data Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "def change_size(image):\n",
    "    img = array_to_img(image, scale=False) #returns PIL Image\n",
    "    img = img.resize((75, 75)) #resize image\n",
    "    img = img.convert(mode='RGB') #makes 3 channels\n",
    "    arr = img_to_array(img) #convert back to array\n",
    "    return arr.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr_75 = [change_size(img) for img in x]\n",
    "del x\n",
    "train_arr_75 = np.array(train_arr_75)\n",
    "train_arr_75.shape\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "#from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "#from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "#print(\"BEFORE PREPROCESS:\")\n",
    "#print(train_arr_75)\n",
    "train_arr_75 = preprocess_input(train_arr_75)\n",
    "train_arr_75 = np.array(train_arr_75)\n",
    "train_arr_75 = train_arr_75.astype('float32')\n",
    "train_arr_75 /= 255\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(train_arr_75,y, test_size=0.1, random_state=1, stratify=y)\n",
    "\n",
    "#Model1\n",
    "image_gen1 = ImageDataGenerator(\n",
    "    #samplewise_center=True, don't\n",
    "    #featurewise_center=True, don't\n",
    "    #featurewise_std_normalization=True, don't\n",
    "    #samplewise_std_normalization = True,# accuracy -0.83, better confusion on class4\n",
    "    #zca_whitening = True,\n",
    "        zoom_range=0.2, # randomly zoom into images\n",
    "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        #20 - 0.836\n",
    "        width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n",
    "        #0.1-  0.823, 0.4 - 0.73, 0.3-0.86\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        #0.3-0.77\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "train_generator = image_gen1.flow(train_images, \n",
    "                                 train_labels,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                seed=42)\n",
    "valid_generator = image_gen1.flow(test_images,\n",
    "                                 test_labels,\n",
    "                                batch_size=16,\n",
    "                                shuffle=True)\n",
    "\n",
    "#print(train_arr_75)\n",
    "#del train_arr_75 #saves RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 75, 75, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 16,819,014\n",
      "Trainable params: 16,819,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# example of loading the inception v3 model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "#from classification_models.resnet import ResNet18, preprocess_input\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "#from tensorflow.keras.layers.normalization import BatchNormalization\n",
    "import math \n",
    "def kaiming(shape, dtype=None):\n",
    "    return tf.random.normal(shape, dtype=dtype)*math.sqrt(2./shape[0])\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "model = Sequential()\n",
    "input_tensor = Input(shape=(75, 75, 3))\n",
    "model = VGG16(weights = \"imagenet\",include_top=False, input_shape=(75, 75, 3))\n",
    "#model = ResNet18(input_shape=(224,224,3), weights='imagenet', classes=1000)\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "x2 = Dropout(.1)(flat1)\n",
    "class1 = Dense(1024, activation='relu')(x2)\n",
    "x2 = Dropout(.5)(class1)\n",
    "output = Dense(6, activation='softmax')(class1)\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Do not use default learning rate since it is too high!\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 75, 75, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 16,819,014\n",
      "Trainable params: 16,819,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "input_tensor = Input(shape=(75, 75, 3))\n",
    "model2 = VGG16(weights = \"imagenet\",include_top=False, input_shape=(75, 75, 3))\n",
    "#model = ResNet18(input_shape=(224,224,3), weights='imagenet', classes=1000)\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model2.layers[-1].output)\n",
    "x2 = Dropout(.1)(flat1)\n",
    "class1 = Dense(1024, activation='relu')(x2)\n",
    "x2 = Dropout(.5)(class1)\n",
    "output = Dense(6, activation='softmax')(class1)\n",
    "model2 = Model(inputs=model2.inputs, outputs=output)\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Do not use default learning rate since it is too high!\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Ensemble_test_Model_1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('Ensemble_test_Model_2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = np.load('E:/Kaggle2/test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = test_ds['arr_0']\n",
    "y2 = y2.reshape(60000,28,28,1)\n",
    "#y2 = [change_size(img) for img in y2]\n",
    "#y2 = preprocess_input(y2)\n",
    "\n",
    "\n",
    "#y2 = np.array(y2)\n",
    "#y2 = y2.astype('float32')\n",
    "#y2 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array([change_size(img) for img in y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 75, 75, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.float32(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = preprocess_input(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y2.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros( (y2.shape[0],6) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results + model.predict(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results + model2.predict(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.argmax(results,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, ..., 5, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "t_dataframe=pd.DataFrame(results, columns=['Category']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataframe[\"Id\"] = t_dataframe.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is displayed below:\n",
      "0.8866666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22,  1,  0,  1,  1,  0],\n",
       "       [ 0, 20,  0,  1,  4,  0],\n",
       "       [ 0,  0, 24,  0,  1,  0],\n",
       "       [ 0,  0,  0, 24,  0,  1],\n",
       "       [ 0,  0,  0,  3, 21,  1],\n",
       "       [ 0,  0,  0,  0,  3, 22]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAHWCAYAAACyvxlPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAApnUlEQVR4nO3deZxU1Zn/8e9TTSMRDbIINDQ/wUDikkSJ4JI4KkFBBYQZo8YJaowJWTDqGBeMZoyocUMjjiaCxrC4IBoVF2REEhdGRVDQYVFkExpa0QRNJBig6/n9QYVp2bpoquqec+vz5lWv7rq91LcPt+iH55x7ytxdAAAAockkHQAAAGBbKFIAAECQKFIAAECQKFIAAECQKFIAAECQKFIAAECQKFIAAMBOM7N7zGy1mc2td6yVmU01s3dyb1vW+9hlZrbIzN42s775PAZFCgAAaIwxko7f4tgwSdPcvZukabn7MrMDJH1b0oG5r/mNmVU09AAUKQAAYKe5+wuS/rLF4YGSxubeHytpUL3jE9z9H+6+VNIiSYc29BgUKQAAoFDauXutJOXets0d7yhpRb3Pq8kd26EmBY+3NfbdBwCUGyvlg234cEnBf9c23fsLP5Q0pN6h0e4+upHfblvj0WDmUhQpAAAgMrmCZGeLkvfNrMrda82sStLq3PEaSZ3qfV61pFUNfTOmewAAiF22rvC3xnlc0lm598+SNKne8W+b2W5m1kVSN0mvNvTN6KQAAICdZmYPSDpGUhszq5F0paTrJU00s3MkLZd0iiS5+zwzmyhpvqSNkoa6e4OVkLkXfckIa1IAAOWmtGtS3n+74L9rK9t9qaQ/w7Yw3QMAAILEdA8AALHLZpNOUBQUKQAARM49nUUK0z0AACBIdFIAAIhdSqd76KQAAIAg0UkBACB2KV2TQpECAEDsGr9DbNCY7gEAAEGikwIAQOxSOt1DJwUAAASJTgoAALFL6SXIFCkAAESOHWcBAABKiE4KAACxS+l0D50UAAAQJDopAADEjjUpAAAApUMnBQCA2KV0W3yKFAAAYsd0DwAAQOnQSQEAIHZcggwAAFA6dFIAAIhdStekUKQAABC7lE73FL1IOWWfgcV+iFSY9N5rSUeIRtY96QhRyJglHQEpw3MvfxvXr0w6QirQSQEAIHLu6dwnhYWzAAAgSHRSAACIHQtnAQBAkFK6cJbpHgAAECQ6KQAAxC6l0z10UgAAQJDopAAAELtsOi9BpkgBACB2TPcAAACUDp0UAABixyXIAAAApUMnBQCA2LEmBQAAoHTopAAAELuUrkmhSAEAIHYpLVKY7gEAAEGikwIAQOTc07njLJ0UAAAQJDopAADELqVrUihSAACIHfukAAAAlA6dFAAAYpfS6R46KQAAIEh0UgAAiF1K16RQpAAAEDume+LUuqqNrpxwjX497XbdMvW/dOLZ/SVJZ/z8u7p12h0aMWWkLh51mXb/fPOEk4Zl9KgRqlkxR7NffzbpKMHr2+cYzZv7gt6aP12XXDw06TjB4pzKD+OUP5576Zf6IqWurk7jrrlH/9H7XP180CXqe+aJqu7WSW+8OEcX9vmpLjr+fK1aulL/+pOTk44alHHjH1L/AYOTjhG8TCaj20Zeq/4DBusrB/XSaacN0v77d0s6VpA4p/LDOOWH594WPFv4WwBSX6R8tHqNls5dIkn6dO06rVxUo1btWunNF+coW7fpL+Gd2QvVuqpNkjGDM336DK1Z81HSMYJ3aM/uWrx4mZYuXa4NGzZo4sRJOmlA36RjBYlzKj+MU3547pWHBtekmNl+kgZK6ijJJa2S9Li7LyhytoLbu7qtuhy4r96Zs/Azx3ud2lsvPTk9oVSIWYeO7bWiZtXm+zUra3Voz+4JJgLKA8+9LZTjmhQzu1TSBEkm6VVJM3PvP2Bmw4ofr3Ca7d5MF915qX4//G6t+2Td5uP/du4pym7M6sVHn08wHWJlZlsdc/cEkgDlhedeeWiok3KOpAPdfUP9g2Z2i6R5kq7f1heZ2RBJQyTpa62+qn336LzrSXdBRZMK/ezOYXrxsef16pRXNh8/+uReOqR3D111+i8STIeYraypVafqDpvvV3esUm3t+wkmAsoDz70tlGMnRVJWUodtHK/KfWyb3H20u/dw9x5JFyiS9OMbf6qVi1boybsf33zs4KO7a9CPT9YN51yr9Z+uTzAdYjZz1hx17dpFnTt3UmVlpU49daCeePKZpGMBqcdzbwspXTjbUCflAknTzOwdSStyx/6fpK6Szi1iroLZr8f+OvrkXnp3wTLdNPnXkqT7b7pX3/vlD9SkaaV+ce9VkqSFsxfqrst/m2TUoIwfd7uOOuoItWnTSksWz9Twq2/WmDETko4VnLq6Op1/wRWa/NT9qshkNGbsg5o/f2HDX1iGOKfywzjlh+deebCG5vDMLCPpUG1aOGuSaiTNdPe6fB7glH0GMkmYh0nvvZZ0hGhkmXfOS2Ybc/bAruC5l7+N61eW9Am47vERBf/L+dxJFyX+j0iDV/e4e1bSKw19HgAAQCGxLT4AALELZA1JoVGkAAAQuzK9ugcAACARdFIAAIhdSqd76KQAAIAg0UkBACB2KV2TQpECAEDsUlqkMN0DAACCRCcFAIDYpXQ3YDopAAAgSHRSAACIHWtSAAAASodOCgAAsUtpJ4UiBQCA2LHjLAAAQOnQSQEAIHYpne6hkwIAABrFzP7DzOaZ2Vwze8DMmplZKzObambv5N62bOz3p0gBACB27oW/NcDMOko6T1IPd/+ypApJ35Y0TNI0d+8maVrufqNQpAAAELtstvC3/DSR9DkzayJpd0mrJA2UNDb38bGSBjX2x6JIAQAAO83dV0oaIWm5pFpJH7v7M5LauXtt7nNqJbVt7GNQpAAAELsidFLMbIiZzap3G1L/IXNrTQZK6iKpg6TmZja4kD8WV/cAAICtuPtoSaN38CnHSlrq7h9Ikpk9Iunrkt43syp3rzWzKkmrG5uBTgoAALHzbOFvDVsu6XAz293MTFJvSQskPS7prNznnCVpUmN/LDopAABEzrMNX41T8Md0n2FmD0t6XdJGSbO1qfOyh6SJZnaONhUypzT2MShSAABAo7j7lZKu3OLwP7Spq7LLKFIAAIhdSnecLXqR8mjtrGI/RCqc0L570hGi8fR7s5OOgBRpXtks6QjR+Nv6dUlHQJmhkwIAQOx4FWQAAIDSoZMCAEDsEri6pxQoUgAAiF1KF84y3QMAAIJEJwUAgNjRSQEAACgdOikAAMTOWTgLAABCxHQPAABA6dBJAQAgdindJ4VOCgAACBKdFAAAYpfS1+6hSAEAIHZM9wAAAJQOnRQAACLnXIIMAABQOnRSAACIHWtSAAAASodOCgAAseMSZAAAECSmewAAAEqHTgoAALHjEmQAAIDSoZMCAEDsWJOSDn37HKN5c1/QW/On65KLhyYdJxhtqtro2gm/0m+m/VZ3PHuHBnzvJEnSHi320PD7rtao50dr+H1Xq3mL5gknDQ/nVH5GjxqhmhVzNPv1Z5OOErxMJqPn/+dxTXhodNJRgsZzrx7PFv4WgLIqUjKZjG4bea36DxisrxzUS6edNkj7798t6VhBqKur0z3X/E4/6f1jXTTwIvU7s586deukbw09RW/+zxv64dFD9Ob/vKFv/eSUpKMGhXMqf+PGP6T+AwYnHSMKP/rJd7Xw7UVJxwgaz73yUFZFyqE9u2vx4mVaunS5NmzYoIkTJ+mkAX2TjhWENavXaPHcxZKkdWvXacWiFWrdvrUOO+4wTXt4miRp2sPTdHifw5OMGRzOqfxNnz5Da9Z8lHSM4HXo0F59jj9G48ZOTDpK0HjubSHrhb8FoKyKlA4d22tFzarN92tW1qpDh/YJJgpT2+q2+sKB++rt2W9rrzZ7ac3qNZI2FTJ7tdkr2XCB4ZxCof3qxit05RU3KBvIL4lQ8dwrD40uUszs7EIGKQUz2+qYO/8Q1Nds92a6bNTPdddVd2ndJ+uSjhM8zikUUt/je+nDD/6sN+bMSzpK8HjufZZnswW/hWBXOilXbe8DZjbEzGaZ2axsdu0uPERhraypVafqDpvvV3esUm3t+wkmCktFkwpdNurneu7R5/TylJclSR99+JFatm0pSWrZtqU++vCjBBOGh3MKhXTY4Yfo+BN76415z+l3Y27Vvxx9hEbdfXPSsYLEc28L5TjdY2Zvbuf2v5Labe/r3H20u/dw9x6ZTDhXg8ycNUddu3ZR586dVFlZqVNPHagnnnwm6VjBOO+m87Vi0QpNuvuxzcdenTpDvb/VW5LU+1u9NWPqjITShYlzCoU0/Jcj9OUvHamDDjxG53z3Ar34/Mv64fd/lnSsIPHcKw8N7ZPSTlJfSWu2OG6SXipKoiKqq6vT+RdcoclP3a+KTEZjxj6o+fMXJh0rCAf0PEDfPPmbWrpgqUY+fZskadyN4/Twbx7Wpb8dpuNO66MPVn2g6390XcJJw8I5lb/x427XUUcdoTZtWmnJ4pkafvXNGjNmQtKxECmee1sIpPNRaLajOTwz+52k37v79G187H53//eGHqBJ047pHLkCO6F996QjROPp92YnHSEKmW3M2WNrzSubJR0hGn9bzzq1fG1cv7KkT8BPLv7Xgv+u3eOmRxP/R2SHnRR3P2cHH2uwQAEAACUQyOZrhVZWlyADAIB48No9AADELqVrUihSAACInKe0SGG6BwAABIlOCgAAsaOTAgAAUDp0UgAAiF0gr7VTaBQpAADEjukeAACA0qGTAgBA7OikAAAAlA6dFAAAIrejFwuOGUUKAACxY7oHAACgdOikAAAQOzopAAAApUMnBQCAyPEqyAAAACVEJwUAgNiltJNCkQIAQOzS+fqCTPcAAIAw0UkBACByLJwFAAAoITopAADELqWdFIoUAABix8JZAACA0qGTEoin35uddIRonF51WNIRovBA7YykI0Rh7YZPk44A7DIWzgIAAJQQnRQAAGKX0jUpFCkAAESO6R4AAIASopMCAEDsUjrdQycFAAAEiU4KAACR85R2UihSAACIXUqLFKZ7AABAkOikAAAQubRO99BJAQAAQaKTAgBA7OikAAAAlA6dFAAAIseaFAAAECTPFv6WDzPby8weNrO3zGyBmR1hZq3MbKqZvZN727KxPxdFCgAAaKyRkqa4+36SDpK0QNIwSdPcvZukabn7jcJ0DwAAkUtiusfMPi/pKEnflSR3Xy9pvZkNlHRM7tPGSnpO0qWNeQw6KQAAoDH2lfSBpN+b2Wwzu9vMmktq5+61kpR727axD0CRAgBA7NwKfjOzIWY2q95tyBaP2kTS1yT91t27S1qrXZja2RamewAAiFwxpnvcfbSk0Tv4lBpJNe4+I3f/YW0qUt43syp3rzWzKkmrG5uBTgoAANhp7v6epBVm9qXcod6S5kt6XNJZuWNnSZrU2MegkwIAQOQ8a0k99E8l3WdmTSUtkXS2NjVAJprZOZKWSzqlsd+cIgUAADSKu8+R1GMbH+pdiO9PkQIAQOTSuuMsRQoAAJFzT2y6p6hYOAsAAIJUdkVK3z7HaN7cF/TW/Om65OKhSccJFuO0fa2qWuuyCVfp+mm36bqpt6rP2f0+8/EThwzU+Hcf0R4t90woYZg4p/IzetQI1ayYo9mvP5t0lOBxTv2fpF67p9jKqkjJZDK6beS16j9gsL5yUC+ddtog7b9/t6RjBYdx2rG6uqzuv2ashvU+T1cNGqZjzzxBHbpVS9pUwBx45Ff1Yc0HCacMC+dU/saNf0j9BwxOOkbwOKfKQ4NFipntZ2a9zWyPLY4fX7xYxXFoz+5avHiZli5drg0bNmjixEk6aUDfpGMFh3HasY9Xr9G7c5dIkj5d+6lWLapRq3atJUnf+c/v6cHrxsvdk4wYHM6p/E2fPkNr1nyUdIzgcU59lmet4LcQ7LBIMbPztGkTlp9Kmpt70aB/+lUxgxVDh47ttaJm1eb7NStr1aFD+wQThYlxyl+b6r21z4FdtGjOQnU/tqfWvPdnLV+wLOlYweGcQqFxTpWHhq7u+YGkQ9z9EzPrLOlhM+vs7iMlbbfMyu3vP0SSrKKFMpnmhcq7S8y2jsz/eLfGOOVnt92b6bw7L9F9w+9RdmOdBp57sm44Y3jSsYLEOYVC45z6rLT+6A0VKRXu/okkufsyMztGmwqVfbSDIqX+fv9NmnYMZuhW1tSqU3WHzferO1aptvb9BBOFiXFqWEWTCp1358V66bEXNGvKDFV/6f9p707tdO3Tt0jatDbl6qdG6JcDL9XHH3yUbNgAcE6h0DinPiuU6ZlCa2hNyntmdvA/7+QKlv6S2kj6ShFzFcXMWXPUtWsXde7cSZWVlTr11IF64slnko4VHMapYd+/cahWLVqpKXc/IUmqeXu5hh5yti488ke68Mgf6S+1f9Yv+l1EgZLDOYVC45wqDw11Us6UtLH+AXffKOlMMxtVtFRFUldXp/MvuEKTn7pfFZmMxox9UPPnL0w6VnAYpx37Yo/9dOTJx2j5gmW6ZvLNkqSHbrpPb/zp9YSThYtzKn/jx92uo446Qm3atNKSxTM1/OqbNWbMhKRjBYdz6rPS2kmxYs/hhTTdg3Q4veqwpCNE4YHaGQ1/EpTZxtoGbFs2rQsfimDj+pUlPbGWHXxcwf9yOs+ZmviTg23xAQCIXFrrR4oUAAAil9bpnrLacRYAAMSDTgoAAJHjVZABAABKiE4KAACRC+VViwuNIgUAgMhlme4BAAAoHTopAABEjoWzAAAAJUQnBQCAyLGZGwAAQAnRSQEAIHK8dg8AAAgS0z0AAAAlRCcFAIDIsZkbAABACdFJAQAgcmndzI0iBQCAyKX16h6mewAAQJDopAAAEDkWzgIAAJQQnRQAACLHwlkAABAkFs4CAACUEJ0UAAAil9aFsxQpiM4DtTOSjhCF06sOSzpCFDif8pexdP4iRLgoUgAAiFxaF86yJgUAAASJTgoAAJFjTQoAAAhSSq9AZroHAACEiU4KAACRS+t0D50UAAAQJDopAABELq2XIFOkAAAQuWzSAYqE6R4AABAkOikAAETOlc7pHjopAAAgSHRSAACIXDalu7lRpAAAELks0z0AAAClQycFAIDIsXAWAACghOikAAAQOTZzAwAAKCE6KQAARC6ta1IoUgAAiBzTPQAAACVEJwUAgMjRSQEAACghOikAAESOhbMAACBI2XTWKOU33dO3zzGaN/cFvTV/ui65eGjScYLFOOWPsdq2VlWtddmEq3T9tNt03dRb1efsfp/5+IlDBmr8u49oj5Z7JpQwTJxP+Rk9aoRqVszR7NefTToKiqisipRMJqPbRl6r/gMG6ysH9dJppw3S/vt3SzpWcBin/DFW21dXl9X914zVsN7n6apBw3TsmSeoQ7dqSZsKmAOP/Ko+rPkg4ZRh4XzK37jxD6n/gMFJxwhGVlbwWwgaLFLM7FAz65l7/wAzu9DMTix+tMI7tGd3LV68TEuXLteGDRs0ceIknTSgb9KxgsM45Y+x2r6PV6/Ru3OXSJI+XfupVi2qUat2rSVJ3/nP7+nB68bL3ZOMGBzOp/xNnz5Da9Z8lHQMFNkOixQzu1LSbZJ+a2bXSbpd0h6ShpnZ5SXIV1AdOrbXippVm+/XrKxVhw7tE0wUJsYpf4xVftpU7619DuyiRXMWqvuxPbXmvT9r+YJlSccKDucTGsuLcAtBQwtnvyXpYEm7SXpPUrW7/9XMbpI0Q9K12/oiMxsiaYgkWUULZTLNCxZ4V5ht3b7if3JbY5zyx1g1bLfdm+m8Oy/RfcPvUXZjnQaee7JuOGN40rGCxPmExirXfVI2unudu/9d0mJ3/6skufs67WBM3H20u/dw9x6hFCiStLKmVp2qO2y+X92xSrW17yeYKEyMU/4Yqx2raFKh8+68WC899oJmTZmhtvu0196d2unap2/RLdPvVKuq1rr6qRFqsfdeSUcNAucT8FkNFSnrzWz33PuH/POgmbVQhIXbzFlz1LVrF3Xu3EmVlZU69dSBeuLJZ5KOFRzGKX+M1Y59/8ahWrVopabc/YQkqebt5Rp6yNm68Mgf6cIjf6S/1P5Zv+h3kT7+4KNkgwaC8wmNlTUr+C0EDU33HOXu/5Akd69flFRKOqtoqYqkrq5O519whSY/db8qMhmNGfug5s9fmHSs4DBO+WOstu+LPfbTkScfo+ULlumayTdLkh666T698afXE04WLs6n/I0fd7uOOuoItWnTSksWz9Twq2/WmDETko6FArNiz3c2adqRCVUgAadXHZZ0hCg8UDsj6QjRyATyv+sYrP9HTUkH66Gq7xT8d+0ptfcl/hdeVvukAACAeLAtPgAAkYtukWieKFIAAIgcr90DAABQQhQpAABELsnX7jGzCjObbWZP5u63MrOpZvZO7m3Lxv5cFCkAAGBXnC9pQb37wyRNc/dukqbl7jcKRQoAAJFL6rV7zKxaUj9Jd9c7PFDS2Nz7YyUNatxPxcJZAACil+DC2VslXSJpz3rH2rl7rSS5e62ZtW3sN6eTAgAAtmJmQ8xsVr3bkC0+3l/Sand/rVgZ6KQAABC5YuyT4u6jJY3ewad8Q9JJZnaipGaSPm9m90p638yqcl2UKkmrG5uBTgoAANhp7n6Zu1e7e2dJ35b0R3cfLOlx/d/r+50laVJjH4NOCgAAkQvsRfKulzTRzM6RtFzSKY39RhQpAABELukdZ939OUnP5d7/s6Tehfi+TPcAAIAg0UkBACByaX2BQTopAAAgSHRSAACIHJ0UAACAEqKTAgBA5Dzhq3uKhSIFAIDIMd0DAABQQnRSAACIHJ0UAACAEqKTAgBA5AJ77Z6CoUgBACBySb92T7Ew3QMAAIJEJwVIqUc/mJ10hCgMaP+1pCNE46n3OadCxcJZAACAEqKTAgBA5NLaSaFIAQAgcmm9uofpHgAAECQ6KQAARI5LkAEAAEqITgoAAJFL68JZOikAACBIdFIAAIhcWq/uoUgBACBy2ZSWKUz3AACAINFJAQAgciycBQAAKCE6KQAARC6dK1IoUgAAiB7TPQAAACVEJwUAgMjx2j0AAAAlRCcFAIDIpXUzN4oUAAAil84ShekeAAAQKDopAABEjkuQAQAASohOCgAAkWPhLAAACFI6SxSmewAAQKDKrkjp2+cYzZv7gt6aP12XXDw06TjBYpzyx1g1bLfdmuq5Fx7Ty69M1sxZ/63Lr7gg6UjBaF3VRsMnXKv/mvYbjXz2DvX/3gBJ0tf7fUMjn71Df1g2SV/4ateEU4Zn9KgRqlkxR7NffzbpKEHIFuEWgrIqUjKZjG4bea36DxisrxzUS6edNkj7798t6VjBYZzyx1jl5x//WK9+J/y7jjj8RB1xeD8de9zR6tnz4KRjBSFbV6cx19yjn/b+iS4deJFOOLOfqrt10vK339UNQ36l+TPmJR0xSOPGP6T+AwYnHQNFttNFipmNK0aQUji0Z3ctXrxMS5cu14YNGzRx4iSdNKBv0rGCwzjlj7HK39q1f5ckVVY2UWVlk9TOoe+sNavXaMncxZKkT9euU82iFWrdvrVqFtVo1ZKVCacL1/TpM7RmzUdJxwhGVl7wWwh2uHDWzB7f8pCkXma2lyS5+0lFylUUHTq214qaVZvv16ys1aE9uyeYKEyMU/4Yq/xlMhlNf+kJ7bvvPho9arxmzZyTdKTg7F3dVl0O/IIWzn476ShAEBq6uqda0nxJd2vT4mGT1EPSzUXOVRRmW79MpHsY1WJIGKf8MVb5y2az+vrh/dSixZ56YMIoHXDAFzV//sKkYwWj2e7NdOmoy3TPVXdp3Sfrko6DyKT1X52Gpnt6SHpN0uWSPnb35yStc/fn3f357X2RmQ0xs1lmNiubXVu4tLtoZU2tOlV32Hy/umOVamvfTzBRmBin/DFWO+/jj/+mF198Rcced3TSUYJR0aRCl4y6TC88+pxemfJy0nEQobJcOOvuWXf/taSzJV1uZrcrj71V3H20u/dw9x6ZTPMCRd11M2fNUdeuXdS5cydVVlbq1FMH6oknn0k6VnAYp/wxVvlp06aVWrTYU5LUrNlu6tXrSC1cuDjhVOEYetN5qlm0Qo/fPSnpKEBQ8trMzd1rJJ1iZv0k/bW4kYqnrq5O519whSY/db8qMhmNGfsg7eZtYJzyx1jlp137thp91whVZCqUyZgeeeQpTXn6j0nHCsL+PQ9Qr5O/qWULluqWp0dKku69cZwqm1bq+8N/qBatWuiK3/+nls5fquFnXJlw2nCMH3e7jjrqCLVp00pLFs/U8Ktv1pgxE5KOlRhP6YSPFXv+vEnTjukcOSBwzZo0TTpCFI5r8+WkI0TjqfdnJx0hGuv/UbP1grUiOq/zaQX/XXvbsgdL+jNsC9viAwAQuVDWkBQaRQoAAJELZV+TQiurHWcBAEA86KQAABC5dPZR6KQAAIBA0UkBACByaV2TQpECAEDk0np1D9M9AAAgSHRSAACIXFp3nKWTAgAAgkQnBQCAyLEmBQAAoITopAAAELm0rkmhSAEAIHJM9wAAAJQQnRQAACKX9XRO99BJAQAAQaKTAgBA5NLZR6FIAQAgeml9gUGmewAAQJDopAAAELm07pNCJwUAAASJTgoAAJFL62ZuFCkAAESOhbMAAAAlRCcFAIDIpXXhLEUKkFKfblyfdIQoTP1wbtIRojGw/SFJR0CZoUgBACByaV04y5oUAAAQJIoUAAAi5+4FvzXEzDqZ2Z/MbIGZzTOz83PHW5nZVDN7J/e2ZWN/LooUAAAil5UX/JaHjZJ+5u77Szpc0lAzO0DSMEnT3L2bpGm5+41CkQIAAHaau9e6++u59/8maYGkjpIGShqb+7SxkgY19jFYOAsAQOSSXjhrZp0ldZc0Q1I7d6+VNhUyZta2sd+XTgoAANiKmQ0xs1n1bkO283l7SPqDpAvc/a+FzEAnBQCAyBVjMzd3Hy1p9I4+x8wqtalAuc/dH8kdft/MqnJdlCpJqxubgU4KAACRS2LhrJmZpN9JWuDut9T70OOSzsq9f5akSY39ueikAACAxviGpDMk/a+Zzckd+7mk6yVNNLNzJC2XdEpjH4AiBQCAyOWzr0kRHnO6JNvOh3sX4jGY7gEAAEGikwIAQOSSvgS5WChSAACIXDGu7gkB0z0AACBIdFIAAIhcnq+1Ex06KQAAIEh0UgAAiFwSlyCXAp0UAAAQJDopAABELq1rUihSAACIHJcgAwAAlBCdFAAAIpdl4SwAAEDp0EkBACBy6eyjUKQAABC9tF7dU3bTPX37HKN5c1/QW/On65KLhyYdJ1iMU/4Yq/wwTvnZbbemeu6Fx/TyK5M1c9Z/6/IrLkg6UjBaV7XRlROu0a+n3a5bpv6XTjy7vyTpjJ9/V7dOu0MjpozUxaMu0+6fb55wUhSKFXuXuiZNOwZT3mUyGS2Y96KOP/F01dTU6pWXJ2vwGT/RggXvJB0tKIxT/hir/IQ8Ts2aNE06wlaaN99da9f+XU2aNNHUaQ/pkouu0syZc5KOpRP2/mqij79X25Zq2balls5dombNP6cbnrxZNw25Tq3at9bcl95Uti6r7ww7U5J03/XjEs360LuTrJSPd0THXgX/Xfvyyj+V9GfYlp3qpJjZkWZ2oZn1KVagYjq0Z3ctXrxMS5cu14YNGzRx4iSdNKBv0rGCwzjlj7HKD+O0c9au/bskqbKyiSorm6S0kb/zPlq9RkvnLpEkfbp2nVYuqlGrdq305otzlK3LSpLemb1QravaJBkTBbTDIsXMXq33/g8k3S5pT0lXmtmwImcruA4d22tFzarN92tW1qpDh/YJJgoT45Q/xio/jNPOyWQyeumVp7T03Vn647TpmhVAFyU0e1e3VZcD99U7cxZ+5nivU3tr9nOvJZQqOe5e8FsIGuqkVNZ7f4ik49z9Kkl9JH2naKmKxGzrzlUofxEhYZzyx1jlh3HaOdlsVl8/vJ++1O0I9ehxkA444ItJRwpKs92b6aI7L9Xvh9+tdZ+s23z83849RdmNWb346PMJpktGVl7wWwgaKlIyZtbSzFpr0/qVDyTJ3ddK2ri9LzKzIWY2y8xmZbNrCxh316ysqVWn6g6b71d3rFJt7fsJJgoT45Q/xio/jFPjfPzx3/Tii6/o2OOOTjpKMCqaVOhndw7Ti489r1envLL5+NEn99IhvXto5Pk3J5gOhdZQkdJC0muSZklqZWbtJcnM9pC03QU17j7a3Xu4e49MJpxV1jNnzVHXrl3UuXMnVVZW6tRTB+qJJ59JOlZwGKf8MVb5YZzy16ZNK7VosackqVmz3dSr15FauHBxwqnC8eMbf6qVi1boybsf33zs4KO7a9CPT9YN51yr9Z+uTzBdcrwIf0Kww31S3L3zdj6UlfSvBU9TZHV1dTr/gis0+an7VZHJaMzYBzV//sKGv7DMME75Y6zywzjlr137thp91whVZCqUyZgeeeQpTXn6j0nHCsJ+PfbX0Sf30rsLlummyb+WJN1/07363i9/oCZNK/WLe6+SJC2cvVB3Xf7bJKOiQMrqEmQA2FKIlyCHKulLkGNS6kuQe1T9S8F/186qfTGuS5ABAABKhW3xAQCIXChX4xQaRQoAAJFL6yX9TPcAAIAg0UkBACByaZ3uoZMCAACCRCcFAIDIhbL5WqFRpAAAELksC2cBAABKh04KAACRS+t0D50UAAAQJDopAABELq1rUihSAACIHNM9AAAAJUQnBQCAyKV1uodOCgAACBKdFAAAIseaFAAAgBKikwIAQOTSuiaFIgUAgMgx3QMAAFBCdFIAAIicezbpCEVBJwUAAASJTgoAAJHLpnRNCkUKAACR85Re3cN0DwAACBKdFAAAIsd0TyNtXL+y2A8BAABSiE4KAACRS+uaFIoUAAAil9Zt8Vk4CwAAgkQnBQCAyPHaPQAAACVEJwUAgMildeEsnRQAABAkOikAAESOzdwAAECQmO4BAAAoITopAABEjs3cAAAASohOCgAAkUvrmhSKFAAAIpfWq3uY7gEAAEGikwIAQOTSOt1DJwUAAASJTgoAAJFL6yXIFCkAAETOWTgLAABQOnRSAACIXFqne+ikAACAINFJAQAgclyCDAAAUEJ0UgAAiFxar+6hSAEAIHJM9wAAANRjZseb2dtmtsjMhhX6+9NJAQAgckl0UsysQtIdko6TVCNpppk97u7zC/UYdFIAAEBjHCppkbsvcff1kiZIGljIB6BIAQAgcl6EWx46SlpR735N7ljBlGK6x0rwGDvFzIa4++ikc8SAscoP45Q/xio/jFN+GKdNNq5fWfDftWY2RNKQeodGbzHW23rMgs47lWsnZUjDn4Icxio/jFP+GKv8ME75YZyKxN1Hu3uPercti8EaSZ3q3a+WtKqQGcq1SAEAALtmpqRuZtbFzJpK+rakxwv5AFzdAwAAdpq7bzSzcyX9t6QKSfe4+7xCPka5FillP3+5Exir/DBO+WOs8sM45YdxSpC7T5Y0uVjf39K6Sx0AAIgba1IAAECQyq5IKfYWvmlhZveY2Wozm5t0lpCZWScz+5OZLTCzeWZ2ftKZQmRmzczsVTN7IzdOVyWdKWRmVmFms83syaSzhMzMlpnZ/5rZHDOblXQeFF5ZTffktvBdqHpb+Eo6vZBb+KaFmR0l6RNJ49z9y0nnCZWZVUmqcvfXzWxPSa9JGsQ59VlmZpKau/snZlYpabqk8939lYSjBcnMLpTUQ9Ln3b1/0nlCZWbLJPVw9w+TzoLiKLdOStG38E0Ld39B0l+SzhE6d69199dz7/9N0gIVeMfFNPBNPsndrczdyud/SDvBzKol9ZN0d9JZgKSVW5FS9C18Ub7MrLOk7pJmJBwlSLkpjDmSVkua6u6M07bdKukSSdmEc8TAJT1jZq/ldkdFypRbkVL0LXxRnsxsD0l/kHSBu/816Twhcvc6dz9Ym3alPNTMmEbcgpn1l7Ta3V9LOkskvuHuX5N0gqShuWlqpEi5FSlF38IX5Se3xuIPku5z90eSzhM6d/9I0nOSjk82SZC+Iemk3FqLCZK+aWb3JhspXO6+Kvd2taRHtWlKHylSbkVK0bfwRXnJLQj9naQF7n5L0nlCZWZ7m9leufc/J+lYSW8lGipA7n6Zu1e7e2dt+vfpj+4+OOFYQTKz5rnF6jKz5pL6SOJqxJQpqyLF3TdK+ucWvgskTSz0Fr5pYWYPSHpZ0pfMrMbMzkk6U6C+IekMbfof75zc7cSkQwWoStKfzOxNbfrPwlR35/Ja7Ip2kqab2RuSXpX0lLtPSTgTCqysLkEGAADxKKtOCgAAiAdFCgAACBJFCgAACBJFCgAACBJFCgAACBJFCgAACBJFCgAACBJFCgAACNL/B8MtbxOEcuE4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "results = np.zeros( (test_images.shape[0],6) ) \n",
    "results = results + model.predict(test_images)\n",
    "results = results + model2.predict(test_images)\n",
    "results = np.argmax(results,axis = 1)\n",
    "Y_val_pred = results\n",
    "\n",
    "\n",
    "test_labels = np.argmax(test_labels, axis = 1)\n",
    "cf_matrix = confusion_matrix(test_labels, Y_val_pred)\n",
    "print(\"Accuracy Score is displayed below:\")\n",
    "\n",
    "print(accuracy_score(test_labels, Y_val_pred))\n",
    "categories = list(np.unique(test_labels))\n",
    "df_cm = pd.DataFrame(cf_matrix,index = categories,\n",
    "  columns = categories)\n",
    "plt.figure(figsize=(10,8))\n",
    "res = sns.heatmap(df_cm, annot=True, vmin=0.0, vmax=100.0)\n",
    "bottom, top = res.get_ylim()\n",
    "res.set_ylim(bottom + 0.5, top - 0.5)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_titles = [\"Id\",\"Category\"]\n",
    "t_dataframe=t_dataframe.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataframe.to_csv(\"E:/kaggleVGGMerge.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
